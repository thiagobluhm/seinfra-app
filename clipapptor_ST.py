import streamlit as st
import os
import fitz  # PyMuPDF
from openai import OpenAI
from docx import Document
import re
from io import BytesIO
from dotenv import load_dotenv
from streamlit import session_state as ss
from streamlit_pdf_viewer import pdf_viewer

# üîπ Carregar vari√°veis de ambiente
load_dotenv()
secretk = os.environ.get("OPENAI_API_KEY")
cliente_openai = OpenAI(api_key=secretk)

# üîπ Fun√ß√£o para extrair texto do PDF
def extract_content(pdf_bytes):
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    extracted_data = []
    for page_num, page in enumerate(doc, start=1):
        extracted_data.append({
            "page_number": page_num,
            "text": page.get_text(),
            "link": f"#page={page_num}"
        })
    return extracted_data

# üîπ Fun√ß√£o para identificar palavras-chave no texto
def find_keywords(text, keywords):
    return [kw for kw in keywords if kw.lower() in text.lower()]

# üîπ Fun√ß√£o para gerar resumos via OpenAI
def generate_summary(text):
    prompt = f"Resuma o seguinte texto em poucas frases mantendo os pontos principais:\n\n{text}"
    try:
        response = cliente_openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Voc√™ √© um assistente que resume textos de forma objetiva."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=150
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Erro ao gerar resumo: {e}"

# üîπ Processamento do PDF
def process_pdf(pdf_bytes):
    keywords = [
        "Governo Federal", "Governo do Estado do Cear√°", "Cear√°", "infraestrutura",
        "sa√∫de", "educa√ß√£o", "seguran√ßa p√∫blica", "investimento", "ministro", 
        "governador", "prefeito", "pol√≠tica", "infraestrutura urbana", "mobilidade urbana",
        "transporte p√∫blico", "energia renov√°vel", "obras p√∫blicas", "hospital", 
        "escolas p√∫blicas", "recursos federais", "recursos estaduais", "moradia", 
        "habita√ß√£o", "economia", "desenvolvimento regional", "assist√™ncia social", 
        "meio ambiente", "√°gua pot√°vel", "saneamento b√°sico", "pontes", "rodovias", 
        "ferrovias", "aeroportos", "portos", "log√≠stica", "seguran√ßa alimentar", 
        "or√ßamento p√∫blico", "pol√≠ticas p√∫blicas", "emendas parlamentares", 
        "licita√ß√£o", "contratos p√∫blicos", "parcerias p√∫blico-privadas", 
        "inova√ß√£o tecnol√≥gica", "tecnologia", "sa√∫de p√∫blica", "sistema √∫nico de sa√∫de",
        "vacina√ß√£o", "doen√ßas infecciosas", "crise h√≠drica", "minist√©rio", 
        "agricultura", "turismo", "ind√∫stria", "com√©rcio exterior", "universidades"
    ]
    extracted_data = extract_content(pdf_bytes)
    filtered_data = []
    
    for page in extracted_data:
        detected_keywords = find_keywords(page["text"], keywords)
        if detected_keywords:
            summary = generate_summary(page["text"])
            filtered_data.append({
                "page_number": page["page_number"],
                "summary": summary,
                "keywords": ", ".join(detected_keywords)
            })
    return filtered_data

# üîπ Streamlit Interface
st.set_page_config(page_title="Clipapptor - IA para Resumo de PDFs", layout="wide")
st.title("üìë Clipapptor - IA para Resumo de PDFs")

# Sidebar com Upload e Bot√£o
with st.sidebar:
    uploaded_file = st.file_uploader("üì§ Fa√ßa upload do PDF", type=["pdf"], key='pdf')
    if st.button("üìÑ Gerar Clippings do Jornal") and uploaded_file:
        with st.spinner("Processando PDF..."):
            resumos = process_pdf(uploaded_file.getvalue())
        ss.resumos = resumos  # Armazena resumos na sess√£o

# Exibir PDF ao lado
col1, col2 = st.columns([2, 3])

with col1:
    if ss.get('pdf'):
        pdf_viewer(input=ss.pdf.getvalue(), width=700)

with col2:
    if ss.get('resumos'):
        for resumo in ss.resumos:
            st.markdown(f"### P√°gina {resumo['page_number']}")
            st.write(f"**Palavras-chave:** {resumo['keywords']}")
            st.write(f"**Resumo:** {resumo['summary']}")
            st.markdown("---")
    else:
        st.warning("Aguardando gera√ß√£o de clipping...")